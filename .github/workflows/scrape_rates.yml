name: Update FCI Data Daily

on:
  schedule:
    - cron: '0 5 * * *' # Ejecuta todos los días a las 05:00 AM UTC (ajusta la hora según tu necesidad)
  workflow_dispatch: # Permite ejecutar manualmente la acción desde GitHub UI

jobs:
  update_data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x' # o '3.9', '3.10', etc.

    - name: Install system dependencies for Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser # Instalar Chromium para Selenium

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt # Esto instalará selenium y webdriver-manager

    - name: Debug - List files before scraper run
      run: ls -lR

    - name: Run FCI Scraper (Real Web Scrape)
      run: python fci_scraper.py

    - name: Debug - List files after scraper run
      run: ls -lR

    - name: Debug - Cat fci_data.json content
      run: cat fci_data.json || echo "fci_data.json not found or empty"
      continue-on-error: true # Permite que este paso falle si el archivo no se genera

    - name: Commit and push changes
      run: |
        git config user.name 'github-actions[bot]'
        git config user.email 'github-actions[bot]@users.noreply.github.com'
        git add fci_data.json
        git commit -m "Automated: Update FCI data via Selenium scrape" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
