name: Daily Financial Data Update

on:
  schedule:
    - cron: '0 5 * * *' # Ejecuta todos los días a las 05:00 AM UTC (ajusta la hora según tu necesidad)
  workflow_dispatch: # Permite ejecutar manualmente la acción desde GitHub UI

jobs:
  update_data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x' # o '3.9', '3.10', etc.

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt # Esto instalará solo las dependencias necesarias (sin Selenium)

    - name: Debug - List files before scraper run
      run: ls -lR

    - name: Run Combined Financial Data Scraper
      run: python fci_scraper.py # Ahora este script hace ambos scrapeos directamente de HTML

    - name: Debug - List files after scraper run
      run: ls -lR

    - name: Debug - Cat fci_data.json content
      run: cat fci_data.json || echo "fci_data.json not found or empty"
      continue-on-error: true

    - name: Debug - Cat tasas_bancos.json content
      run: cat tasas_bancos.json || echo "tasas_bancos.json not found or empty"
      continue-on-error: true

    - name: Commit and push changes
      run: |
        git config user.name 'github-actions[bot]'
        git config user.email 'github-actions[bot]@users.noreply.github.com'
        git add fci_data.json tasas_bancos.json # Añadir ambos archivos
        git commit -m "Automated: Update FCI and Fixed Deposit data via HTML scrape" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
